#!/bin/bash -e

#
# Note: requires the [AWS CLI](http://aws.amazon.com/cli/) to be installed and configured.
#
# EKB FIXME remove more unnecessary files (or just copy a whitelist?)
#

if [[ $1 == "" ]]; then
	echo Usage: $0 filename
	exit 1
fi

set -x
cd $(dirname $0)/..
s=$(pwd)
t=$(mktemp -dt data-analysis-demo.XXXXXX)
us="download.fpcomplete.com/data-analysis-demo/skel/$1.tgz"

git clone . $t/skel
#mkdir -p $t/skel
#cp -r . $t/skel

cd $t/skel

# EKB TODO perhaps would be better to not include these files in the repo to start with
#   (move the import wizard to a separate repo, etc)
rm -rf .git scripts src/FP/ImportWizard data/import-wizard static/flot/examples test src/User*.hs src/main/Main.hs temp src/*UserAnalysis*.hs src/*UserParam*.hs
rmdir src/FP
test -d data && rmdir data

perl -i -pe 's/DataAnalysis.Application.Types.Stock/UserModel/' src/main/Main.hs src/User*.hs src/DataAnalysis/Application/Import.hs

git init
git add --all
git commit -m "Data analysis scaffolding"

tar czf $t/skel.tgz .
aws --region us-east-1 s3 cp $t/skel.tgz s3://$us

cd $s
rm -rf $t

set +x
echo -----------------------------------------------------------------------------
echo Now edit \`src/FP/ImportWizard/Main.hs\` and set the URL that the skeleton is
echo downloaded from to \'https://s3.amazonaws.com/$us\'
echo -----------------------------------------------------------------------------
